## BERT 
> [Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) 
> 
> [BERT解析](https://blog.csdn.net/jiaowoshouzi/article/details/89073944?ops_request_misc=%257B%2522request%255Fid%2522%253A%25227ac260b560f483d6e6ff04adcb6ab510%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=7ac260b560f483d6e6ff04adcb6ab510&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-89073944-null-null.142^v102^pc_search_result_base3&utm_term=Bert&spm=1018.2226.3001.4187)


