# 多模态大模型知识点：
### 1. 多模态大模型领域的 **模态数据对齐**
在多模态大模型领域，**模态数据对齐（Modality Alignment）** 是指通过技术手段将不同模态（如文本、图像、音频、视频等）的数据在语义、时间或空间上建立对应关系，使模型能够理解和融合跨模态信息。

多模态的数据描述的是同一件事，那么就是正样本，不是同一件事就是负样本
有哪些？多模态模型对齐： 
- 1. 语义对齐
定义：将不同模态数据的语义信息映射到同一特征空间，例如将图像的视觉特征与文本的语义特征对齐。
方法：
示例：模型将 “猫在沙发上” 的文本描述与对应语音片段对齐，实现跨模态检索。
- 2. 时间对齐
定义：在时序数据（如视频、音频）中建立模态间的时间同步关系。
示例：视频理解任务中，将语音与画面的动作在时间轴上精确同步。
- 3. 空间对齐
定义：在空间维度上对齐不同模态数据，例如将文本描述中的物体位置与图像中的像素区域对应。
示例：在图像分割任务中，将文本指令中的 “红色汽车” 与图像中的对应区域对齐。


### 2. 多模态大模型领域的 Shot 学习范式

在多模态大模型中，**Shot 学习**（如 Zero-Shot、Few-Shot）指模型利用**有限样本**或**无样本**完成新任务的能力，核心依赖**跨模态对齐**和**预训练知识迁移**。以下是关键概念及分类：


#### 2.1核心概念与分类
| 类型          | 定义                                                                 | 多模态典型应用场景                                                                 |
|---------------|----------------------------------------------------------------------|----------------------------------------------------------------------------------|
| **Zero-Shot** | 无任何目标任务样本，仅靠预训练跨模态对齐完成任务（如文本→图像生成）。 | 跨模态检索（CLIP：输入文本“红色汽车”检索未见图像）、图像描述（BLIP：零样本生成新图像标题）。 |
| **One-Shot**  | 仅用单个样本（图文对/文本指令）学习新任务。                          | 视觉问答（LLaVA：单张图像+问题示例→回答新图像问题）、多模态推理（GPT-4V：单案例教模型识别罕见符号）。 |
| **Few-Shot**  | 少量样本（通常 5-20 个）微调或提示学习。                            | 医学影像诊断（3D-CT-GPT++：少量病例微调→新病灶检测）、多语言图文生成（Flamingo：Few-Shot 跨语言图文对齐）。 |
| **Prompt-Based** | 通过文本/视觉提示（如“描述图像中的动作”）激活预训练知识，无需微调。 | 图像标注（Segment Anything：文本提示分割未见物体）、视频理解（VideoCLIP：自然语言指令解析视频内容）。 |
| **In-Context Learning** | 在输入中嵌入少量示例（上下文），模型通过注意力机制隐式学习模式。     | 多模态推理（Gemini：上下文示例教模型对齐图表数据与文本分析）、跨模态逻辑（MLLM-SAM：上下文图文对→复杂空间关系推理）。 |

