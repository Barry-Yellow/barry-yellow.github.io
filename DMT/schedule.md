# 多模态大模型知识点：
### 1. 多模态大模型领域的 **模态数据对齐**
在多模态大模型领域，**模态数据对齐（Modality Alignment）** 是指通过技术手段将不同模态（如文本、图像、音频、视频等）的数据在语义、时间或空间上建立对应关系，使模型能够理解和融合跨模态信息。

多模态的数据描述的是同一件事，那么就是正样本，不是同一件事就是负样本
有哪些？多模态模型对齐： 
- 1. 语义对齐
定义：将不同模态数据的语义信息映射到同一特征空间，例如将图像的视觉特征与文本的语义特征对齐。
方法：
示例：模型将 “猫在沙发上” 的文本描述与对应语音片段对齐，实现跨模态检索。
- 2. 时间对齐
定义：在时序数据（如视频、音频）中建立模态间的时间同步关系。
示例：视频理解任务中，将语音与画面的动作在时间轴上精确同步。
- 3. 空间对齐
定义：在空间维度上对齐不同模态数据，例如将文本描述中的物体位置与图像中的像素区域对应。
示例：在图像分割任务中，将文本指令中的 “红色汽车” 与图像中的对应区域对齐。


### 2. 多模态大模型领域的 Shot 学习范式

在多模态大模型中，**Shot 学习**（如 Zero-Shot、Few-Shot）指模型利用**有限样本**或**无样本**完成新任务的能力，核心依赖**跨模态对齐**和**预训练知识迁移**。以下是关键概念及分类：

零样本学习是指模型在**未见过特定类别的数据**时，仍能通过已学知识完成对新类别的识别、生成或推理任务。其核心思想是**将模型在训练数据中学到的通用知识迁移到新任务或新领域**，无需额外标注样本。


#### 2.1核心概念与分类
| 类型          | 定义                                                                 | 多模态典型应用场景                                                                 |
|---------------|----------------------------------------------------------------------|----------------------------------------------------------------------------------|
| **Zero-Shot** | 无任何目标任务样本，仅靠预训练跨模态对齐完成任务（如文本→图像生成）。 | 跨模态检索（CLIP：输入文本“红色汽车”检索未见图像）、图像描述（BLIP：零样本生成新图像标题）。 |
| **One-Shot**  | 仅用单个样本（图文对/文本指令）学习新任务。                          | 视觉问答（LLaVA：单张图像+问题示例→回答新图像问题）、多模态推理（GPT-4V：单案例教模型识别罕见符号）。 |
| **Few-Shot**  | 少量样本（通常 5-20 个）微调或提示学习。                            | 医学影像诊断（3D-CT-GPT++：少量病例微调→新病灶检测）、多语言图文生成（Flamingo：Few-Shot 跨语言图文对齐）。 |
| **Prompt-Based** | 通过文本/视觉提示（如“描述图像中的动作”）激活预训练知识，无需微调。 | 图像标注（Segment Anything：文本提示分割未见物体）、视频理解（VideoCLIP：自然语言指令解析视频内容）。 |
| **In-Context Learning** | 在输入中嵌入少量示例（上下文），模型通过注意力机制隐式学习模式。     | 多模态推理（Gemini：上下文示例教模型对齐图表数据与文本分析）、跨模态逻辑（MLLM-SAM：上下文图文对→复杂空间关系推理）。 |
### 3.多模态大模型任务
图片中的文字问题
图片中的细节问题
图片的再编辑能力，保留原本的元素，更改指定的元素。
图片的风格化改造，保持原本的元素，对元素进行重新编辑
图片生成的一致性，比如人物、形象、风格的一致性
提取



将图片进行缺块，然后补全，然后再进行学习。
然后让人工标注一个图片的位置，然后让模型去学习这个位置的描述信息。
自回归的生成模型可以减少未提到的
扩散模型倾向于生成新的内容，而不是修改现有的内容。

多尺度自回归模型

对于不同的颜色维度、形状维度、物体分割维度、语义识别维度、时间维度  都进行学习。
然后将这些维度进行组合，然后进行学习。

VQVAE训练很难 VQ tokenizer。
一次性生成多图会更加厉害的一致性。

diffusion+自回归的控制

神经网络里面加一点硬逻辑呢？会不会输出稳定点

MoE的时候，有模型专门管逻辑，有人专门执行逻辑最后的部分。

分层的生成内容，比如生成图片，可以先生成架构，然后再填空。
架构如果不对的话，就不生成。

多模态有两个阶段，预训练+指令微调。一般都是用训练好的模型直接用。将图片和语言预训练的时候冻结，只训练projector。指令微调的时候解冻。跨注意力层都处于激活状态。
### 多模态的合成方式
1. 采用统一的LM框架，将不同模态的数据进行统一的编码，然后再放入统一的模型进行生成。
2. 跨模态的注意力架构，将图像编码放入多头注意力层，而不是统一输入。